{"pages":[{"title":"about","text":"Github:https://github.com/shuvigoss/ Mail:shuviogss@gmail.com","link":"/about/index.html"}],"posts":[{"title":"【HttpComponents】源码分析1-HttpCore","text":"HttpComponents前身是大名鼎鼎的HttpClient,考虑到架构或者实现上改动太大,HttpComponents诞生了(重写),它将原有HttpClient进行拆分、模块化. 这里我选择从底层往上层分析. HttpCore HttpClient HttpAsyncClient Note: 本次源码分析基于HttpComponents 4.x Let’s Go！ Http协议复习Request 请求行(RequestLine) GET /index.html HTTP/1.1 首部(Headers 细分的话为请求、通用、实体三类) Accept-Encoding: gzip, deflate, sdch CR+LF 空行 主体(Body) xxxx 例子： 123456789GET / HTTP/1.1Host: cn.bing.comConnection: keep-aliveCache-Control: max-age=0Upgrade-Insecure-Requests: 1User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8Accept-Encoding: gzip, deflate, sdchAccept-Language: zh-CN,zh;q=0.8,en;q=0.6,zh-TW;q=0.4,ja;q=0.2 123456Request = Request-Line *(( general-header | request-header | entity-header ) CRLF) CRLF [ message-body ] Response 状态行(StatusLine) HTTP/1.1 200 OK 首部(Headers 细分的话为响应、通用、实体三类) Content-Type: text/html; charset=utf-8 CR+LF 空行 主体(Body) xxxx 例子： 123456789101112HTTP/1.1 200 OKCache-Control: private, max-age=0Content-Length: 49765Content-Type: text/html; charset=utf-8Content-Encoding: gzipVary: Accept-EncodingServer: Microsoft-IIS/8.5P3P: CP=&quot;NON UNI COM NAV STA LOC CURa DEVa PSAa PSDa OUR IND&quot;X-MSEdge-Ref: Ref A: 27150F449DE941A79F25F4D540646A24 Ref B: A5C28C846B068A71F2050ADD7537DB8B Ref C: Tue Sep 6 01:37:39 2016 PSTDate: Tue, 06 Sep 2016 08:37:38 GMT&lt;!DOCTYPE html&gt;..... 123456Response = Status-Line *(( general-header | response-header | entity-header ) CRLF) CRLF [ message-body ] HttpCore请求行: RequestLine-&gt;BasicRequestLine 状态行: StatusLine-&gt;BasicStatusLine 首部: Header-&gt;BasicHeader 主体: HttpEntity-&gt;AbstractHttpEntity-&gt;BasicHttpEntity、StringEntity... 以上是HttpCore对于Http协议进行的抽象以及一些基本的实现. 基本 HttpCore Example (blocking IO)12345678910111213141516171819202122232425262728293031323334353637383940public static void main(String[] args) throws Exception { HttpProcessor httpproc = HttpProcessorBuilder.create().add(new RequestContent()).add(new RequestTargetHost()) .add(new RequestConnControl()).add(new RequestUserAgent(&quot;Test/1.1&quot;)) .add(new RequestExpectContinue(true)).build(); HttpRequestExecutor httpexecutor = new HttpRequestExecutor(); HttpCoreContext coreContext = HttpCoreContext.create(); HttpHost host = new HttpHost(&quot;shuvigoss.win&quot;, 80); coreContext.setTargetHost(host); DefaultBHttpClientConnection conn = new DefaultBHttpClientConnection(8 * 1024); ConnectionReuseStrategy connStrategy = DefaultConnectionReuseStrategy.INSTANCE; try { if (!conn.isOpen()) { Socket socket = new Socket(host.getHostName(), host.getPort()); conn.bind(socket); } BasicHttpRequest request = new BasicHttpRequest(&quot;GET&quot;, &quot;/&quot;); System.out.println(&quot;&gt;&gt; Request URI: &quot; + request.getRequestLine().getUri()); httpexecutor.preProcess(request, httpproc, coreContext); HttpResponse response = httpexecutor.execute(request, conn, coreContext); httpexecutor.postProcess(response, httpproc, coreContext); System.out.println(&quot;&lt;&lt; Response: &quot; + response.getStatusLine()); System.out.println(EntityUtils.toString(response.getEntity())); System.out.println(&quot;==============&quot;); if (!connStrategy.keepAlive(response, coreContext)) { conn.close(); } else { System.out.println(&quot;Connection kept alive...&quot;); } } finally { conn.close(); } } 上面这个例子就是基于 HttpCore 的请求 Demo , 通过构建请求、建立连接、解析返回、关闭连接等一系列操作实现一次 Http 请求,我会基于这款代码逐步阅读以及分析. HttpProcessor1234HttpProcessor httpproc = HttpProcessorBuilder.create().add(new RequestContent()).add(new RequestTargetHost()) .add(new RequestConnControl()).add(new RequestUserAgent(&quot;Test/1.1&quot;)) .add(new RequestExpectContinue(true)).build(); 通过HttpProcessorBuilder构建一个HttpProcessor实例. 12345public interface HttpProcessor extends HttpRequestInterceptor, HttpResponseInterceptor { // no additional methods} HttpProcessor 是用来处理请求前拦截以及请求后拦截,这个理解起来很简单,实际上就是前后拦截处理器. 拿RequestUserAgent为例 123456789101112131415161718192021222324252627282930313233public class RequestUserAgent implements HttpRequestInterceptor { private final String userAgent; public RequestUserAgent(final String userAgent) { super(); this.userAgent = userAgent; } public RequestUserAgent() { this(null); } @Override public void process(final HttpRequest request, final HttpContext context) throws HttpException, IOException { Args.notNull(request, &quot;HTTP request&quot;); if (!request.containsHeader(HTTP.USER_AGENT)) { String s = null; final HttpParams params = request.getParams(); if (params != null) { s = (String) params.getParameter(CoreProtocolPNames.USER_AGENT); } if (s == null) { s = this.userAgent; } if (s != null) { request.addHeader(HTTP.USER_AGENT, s); } } }} 这段代码比较简单,判断请求头是否包含User-Agent首部,如果没有,通过request来获取相关内容并且 set 到 Header 上. HttpRequestExecutor1HttpRequestExecutor httpexecutor = new HttpRequestExecutor(); HttpRequestExecutor 执行器,负责执行HttpProcessor、HttpConnection 完成一次 Http 请求 123httpexecutor.preProcess(request, httpproc, coreContext); //执行前拦截HttpResponse response = httpexecutor.execute(request, conn, coreContext); //请求httpexecutor.postProcess(response, httpproc, coreContext); //执行后拦截 HttpContext123HttpCoreContext coreContext = HttpCoreContext.create();HttpHost host = new HttpHost(&quot;shuvigoss.win&quot;, 80);coreContext.setTargetHost(host); 这个是请求上线文的实现,主要包含一些 host, port, param等等内容. HttpConnection123456DefaultBHttpClientConnection conn = new DefaultBHttpClientConnection(8 * 1024);if (!conn.isOpen()) { Socket socket = new Socket(host.getHostName(), host.getPort()); conn.bind(socket);} HttpConnection是负责具体的连接,由于HttpCore并不提供具体的连接实现,所以他做了个连接的抽象(HttpConnection),在内部有socketHolder、inbuffer、outbuffer、requestWriter、responseParser等实现来处理一次Http请求,内部的具体内容有时间再来说. HttpRequestExecutor execute123456789101112131415161718192021222324252627282930313233public HttpResponse execute( final HttpRequest request, final HttpClientConnection conn, final HttpContext context) throws IOException, HttpException { Args.notNull(request, &quot;HTTP request&quot;); Args.notNull(conn, &quot;Client connection&quot;); Args.notNull(context, &quot;HTTP context&quot;); try { //通过conn发送request HttpResponse response = doSendRequest(request, conn, context); //等待返回 if (response == null) { response = doReceiveResponse(request, conn, context); } return response; } catch (final IOException ex) { closeConnection(conn); throw ex; } catch (final HttpException ex) { closeConnection(conn); throw ex; } catch (final RuntimeException ex) { closeConnection(conn); throw ex; }}private static void closeConnection(final HttpClientConnection conn) { try { conn.close(); } catch (final IOException ignore) { }} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758protected HttpResponse doSendRequest( final HttpRequest request, final HttpClientConnection conn, final HttpContext context) throws IOException, HttpException { Args.notNull(request, &quot;HTTP request&quot;); Args.notNull(conn, &quot;Client connection&quot;); Args.notNull(context, &quot;HTTP context&quot;); HttpResponse response = null; context.setAttribute(HttpCoreContext.HTTP_CONNECTION, conn); context.setAttribute(HttpCoreContext.HTTP_REQ_SENT, Boolean.FALSE); //写请求头到SessionOutputBuffer-&gt;buffer(ByteArrayBuffer) conn.sendRequestHeader(request); //如果是HttpEntityEnclosingRequest的请求(POST,PUT等),检查请求头是否包含Expect: 100-Continue 头,这个是HTTP/1.1特有的头 //意思大致是传输大文本时,先询问server是否支持,如果不支持返回417等错误码,如果支持,返回100 continue //这时候客户端再讲POST内容传到服务器,如果在等待返回超时时间(3000ms)内服务端没有返回,直接POST,下面代码就是对这个头的处理. if (request instanceof HttpEntityEnclosingRequest) { // Check for expect-continue handshake. We have to flush the // headers and wait for an 100-continue response to handle it. // If we get a different response, we must not send the entity. boolean sendentity = true; final ProtocolVersion ver = request.getRequestLine().getProtocolVersion(); if (((HttpEntityEnclosingRequest) request).expectContinue() &amp;&amp; !ver.lessEquals(HttpVersion.HTTP_1_0)) { conn.flush(); // As suggested by RFC 2616 section 8.2.3, we don't wait for a // 100-continue response forever. On timeout, send the entity. if (conn.isResponseAvailable(this.waitForContinue)) { response = conn.receiveResponseHeader(); if (canResponseHaveBody(request, response)) { conn.receiveResponseEntity(response); } final int status = response.getStatusLine().getStatusCode(); if (status &lt; 200) { if (status != HttpStatus.SC_CONTINUE) { throw new ProtocolException( &quot;Unexpected response: &quot; + response.getStatusLine()); } // discard 100-continue response = null; } else { sendentity = false; } } } if (sendentity) { conn.sendRequestEntity((HttpEntityEnclosingRequest) request); } } //调用Scoket OutputStream.flush() 真正写入并传输 conn.flush(); //记录上下文请求已经发送 context.setAttribute(HttpCoreContext.HTTP_REQ_SENT, Boolean.TRUE); return response;} 123456789@Overridepublic void sendRequestHeader(final HttpRequest request) throws HttpException, IOException { Args.notNull(request, &quot;HTTP request&quot;); ensureOpen(); //打开socket this.requestWriter.write(request); //写入缓冲流SessionOutputBuffer onRequestSubmitted(request); //请求提交,子类可根据需求进行定制 incrementRequestCount(); //记录请求的次数} 1234567891011121314151617//this.requestWriter.write(request);@Overridepublic void write(final T message) throws IOException, HttpException { Args.notNull(message, &quot;HTTP message&quot;); //写RequestLine GET / HTTP/1.1 writeHeadLine(message); //写Header for (final HeaderIterator it = message.headerIterator(); it.hasNext(); ) { final Header header = it.nextHeader(); this.sessionBuffer.writeLine (lineFormatter.formatHeader(this.lineBuf, header)); } //清理lineBuf this.lineBuf.clear(); //写空行 this.sessionBuffer.writeLine(this.lineBuf);} 这里就是完整的请求行+首部的写入,里边的 LineBuffer(CharArrayBuffer)就是每行的buffer,可重用,每次洗完都要清理.sessionBuffer是一个连接最终需要传输的报文buffer. 接下来就是处理返回了,由于 Socket 是阻塞的,调用 OutputStream.write 后,服务端就会往InputStream写响应内容. 1234567891011121314151617181920212223protected HttpResponse doReceiveResponse( final HttpRequest request, final HttpClientConnection conn, final HttpContext context) throws HttpException, IOException { Args.notNull(request, &quot;HTTP request&quot;); Args.notNull(conn, &quot;Client connection&quot;); Args.notNull(context, &quot;HTTP context&quot;); HttpResponse response = null; int statusCode = 0; while (response == null || statusCode &lt; HttpStatus.SC_OK) { //创建response并且将头信息读入Response response = conn.receiveResponseHeader(); //读取body if (canResponseHaveBody(request, response)) { conn.receiveResponseEntity(response); } statusCode = response.getStatusLine().getStatusCode(); } // while intermediate response return response;} 12345678910 @Overridepublic HttpResponse receiveResponseHeader() throws HttpException, IOException { ensureOpen(); final HttpResponse response = this.responseParser.parse(); onResponseReceived(response); if (response.getStatusLine().getStatusCode() &gt;= HttpStatus.SC_OK) { incrementResponseCount(); } return response;} 由于解析的过程比较复杂,这里就不具体写了,有个关键点需要记住,由于Socket InputStream 是不能重复读取的,所以在整个解析过程会先读取StatusLine,用于创建Response,而body的数据会封装成Entity(InputStream)用于客户端消费. 基于传统的阻塞IO就介绍完了,通过这个阻塞IO的学习能够了解到HttpCore内部基本的一些功能以及组件.","link":"/2016/09/21/%E3%80%90HttpComponents%E3%80%91%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-HttpCore/"},{"title":"【ReentrantLock源码分析】公平锁&amp;非公平锁","text":"首先，先看一下ReentrantLock类结构。这里可以看到，在ReentrantLock内部，有个Sync内部静态抽象类，该类继承自AbstractQueuedSynchronizer(AQS),并且有2个内部静态类的实现NonfairSync与FairSync，从类的名字就能看出来公平锁与非公平锁是通过Sync实现的。 这里先不对大名鼎鼎的AQS进行介绍，在ReentrantLock内,AQS中state代表着锁的数量,初始值为0,如果有线程获得锁会变为1,由于ReentrantLock是可重入锁,获得锁的线程还是可以继续获得锁,相应的state会在1的基础上继续做++操作,由于对state的操作都是原子的,对它的修改都是通过compareAndSetState(int expect, int update)实现的(CAS) 直接看Sync 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849abstract static class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = -5179523762034025860L; /** * Performs {@link Lock#lock}. The main reason for subclassing * is to allow fast path for nonfair version. */ abstract void lock(); /** * Performs non-fair tryLock. tryAcquire is * implemented in subclasses, but both need nonfair * try for trylock method. */ final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } protected final boolean tryRelease(int releases) { int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free; } //...省略} 其中nonfairTryAcquire是专门为非公平锁获取锁实现。 这里不明白为什么Doug Lea大神不把实现放到NonfairSync中去~ 接下来从代码层面来走一遍lock以及unlock的流程 123456789101112class X { private final ReentrantLock lock = new ReentrantLock(); // ... public void m() { lock.lock(); // block until condition holds try { // ... method body } finally { lock.unlock() } }} 1234567public ReentrantLock() { sync = new NonfairSync();}public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync();} ReentrantLock构造方法默认是非公平模式。 123public void lock() { sync.lock();} lock方法很简单，调用sync(NonfairSync、FairSync)的lock方法，具体调用哪个要看创建的是哪种模式的锁(公平、非公平) lockNonfairSyncCLH队列 12345678final void lock() { //很霸道的直接尝试加锁,并不会考虑是否需要加入CHL(Craig,Landin,Hagersten)队列 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else //如果直接加锁失败,尝试获取 acquire(1);} FairSync1234final void lock() { //尝试获取锁 acquire(1);} acquireacquire方法是AbstractQueuedSynchronizer的方法 12345public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();} tryAcquire(尝试获取)-&gt;失败-&gt;acquireQueued(加入队列) tryAcquireNonfairSync1234567891011121314151617181920final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); //如果当前没有锁,设置锁线程拥有者为自己并返回成功(明显的一个插队现象) if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } //如果自己获得得了锁,再次对state进行++操作,重入 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false;} FairSync12345678910111213141516171819202122protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); //与NonfairSync不同在于,它会判断队列中是否还有排队线程, //如果没有才会设置自己为线程拥有者 if (c == 0) { if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } //重入 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false;} 1234567891011//h != t queue非空public final boolean hasQueuedPredecessors() { // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());} 如果tryAcquire成功,代表加锁成功 end addWaiteracquireQueued(addWaiter(Node.EXCLUSIVE), arg)) 123456789101112131415//放入队列尾部,模式是独占锁模式private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); return node;} 12345678910111213141516private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // 初始化节点,初始化完成后再设置head节点的next节点为等待节点 if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } }} acquireQueued123456789101112131415161718192021222324final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); //如果当前节点pre节点为head节点并且tryAcquire成功, //认为加锁成功,将自己设置为头结点,并返回不是被interrupted. if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } //是否要进行Park操作 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); }} 12345678910111213141516171819202122232425262728293031private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; //pre节点告诉后节点,你需要等待一个Signal,所以你先Park吧~ if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; //pre节点已经Cancelled,那么当前节点要对前边为CANCELLED的进行剔除, //通过do while 循环找到一个waitStatus&gt;0的节点并设置为自己的pre节点 if (ws &gt; 0) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { //如果pre节点状态为0或者PROPAGATE,将pre节点设置为SIGNAL方便下次进来时执行Park /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false;} 12345//park直到被unpark并且返回自己是否是被interrupted唤醒的.private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted();} 123456789101112131415161718192021222324252627282930313233343536373839//这个方法目的在于如果自己是被interrupted,//那么将自己标记为CANCELLED,并判断是否需要唤醒后继线程private void cancelAcquire(Node node) { // Ignore if node doesn't exist if (node == null) return; node.thread = null; // Skip cancelled predecessors Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // predNext is the apparent node to unsplice. CASes below will // fail if not, in which case, we lost race vs another cancel // or signal, so no further action is necessary. Node predNext = pred.next; // Can use unconditional write instead of CAS here. // After this atomic step, other Nodes can skip past us. // Before, we are free of interference from other threads. node.waitStatus = Node.CANCELLED; // If we are the tail, remove ourselves. if (node == tail &amp;&amp; compareAndSetTail(node, pred)) { compareAndSetNext(pred, predNext, null); } else { // If successor needs signal, try to set pred's next-link // so it will get one. Otherwise wake it up to propagate. int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) { Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); } else { unparkSuccessor(node); } node.next = node; // help GC }} selfInterrupt12345//!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg) //!没有获得锁并且获取队列过程中是被interrupted,那么最终标记线程interruptprivate static void selfInterrupt() { Thread.currentThread().interrupt();} unlock1234//调用sync的releasepublic void unlock() { sync.release(1);} 12345678910public final boolean release(int arg) { //尝试释放锁,如果成功,判断是否有等待的头结点,如果有唤醒 if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false;} 12345678910111213protected final boolean tryRelease(int releases) { int c = getState() - releases; //判断是否是线程的拥有者 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free;} 12345678910111213141516171819202122232425262728private void unparkSuccessor(Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ //将waitStatus设置为0 int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ //筛选后继结点waitStatus&lt;=0的节点 Node s = node.next; if (s == null || s.waitStatus &gt; 0) { s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } //唤醒后继节点 if (s != null) LockSupport.unpark(s.thread);} Fair Flow Nonfair Flow endReentrantLock在性能上与synchronized(重量级锁)比较的话(大并发),会高一些(个人认为),毕竟在获取锁时的CAS,以及可重入等等会有那么一些性能上的优势,毕竟synchronized在重量级锁的环境下是没有CAS的,并且锁的竞争一直存在. ReentrantLock相较synchronized关键字的优势有以下几点: 顺序,能保证线程获取锁的顺序(CHL). Condition,使ReentrantLock更加灵活.","link":"/2017/02/09/%E3%80%90ReentrantLock%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%91%E5%85%AC%E5%B9%B3%E9%94%81-%E9%9D%9E%E5%85%AC%E5%B9%B3%E9%94%81/"},{"title":"【HttpComponents】源码分析2-HttpCore&amp;nio","text":"前边介绍了HttpCore里基于传统阻塞IO实现,接下来这篇会比较长,主要是在架构层面上介绍HttpCore+HttpCore NIO. NIO是什么我这里就不具体介绍了,如果有兴趣可以去看别人写的文档.下面这两个链接介绍内容都是一致的,基于老外写的一篇文章. https://java-nio.avenwu.net/index.html http://ifeve.com/overview/ Reactor模式Reactor是处理高并发所设计的一种模式,NIO完全诠释了Reactor设计模式,如果你熟悉了Java的NIO,那么对于Reactor模式也算是有所了解了.我找了很多文章,介绍的都不是很具体,结合NIO和HttpCore NIO来理解Reactor是个不错的选择. 这里有一些文档地址,强烈推荐看一下Doug Lea的文章,里边的多Reactor模式就是HttpCore NIO所使用的。 http://www.blogs8.cn/posts/A1h57fe https://travisliu.gitbooks.io/learn-eventmachine/content/reactorpattern.html http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf 多Reactor设计的好处在于mainReactor负责接受请求而具体的事情由运行在线程池中的subReactor处理的(read、write).HttpCore NIO与这个设计很像,而且也是基于Doug Lea的Reactor所设计的.他在官方文档里也说了. 基本 HttpCore NIO Example (non-blocking IO)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071HttpProcessor httpproc = HttpProcessorBuilder.create() // Use standard client-side protocol interceptors .add(new RequestContent()).add(new RequestTargetHost()).add(new RequestConnControl()) .add(new RequestUserAgent(&quot;Test/1.1&quot;)).add(new RequestExpectContinue(true)).build();// Create client-side HTTP protocol handlerHttpAsyncRequestExecutor protocolHandler = new HttpAsyncRequestExecutor();// Create client-side I/O event dispatchfinal IOEventDispatch ioEventDispatch = new DefaultHttpClientIODispatch(protocolHandler, ConnectionConfig.DEFAULT);// Create client-side I/O reactorfinal ConnectingIOReactor ioReactor = new DefaultConnectingIOReactor();// Create HTTP connection poolBasicNIOConnPool pool = new BasicNIOConnPool(ioReactor, ConnectionConfig.DEFAULT);// Limit total number of connections to just twopool.setDefaultMaxPerRoute(2);pool.setMaxTotal(2);// Run the I/O reactor in a separate threadThread t = new Thread(new Runnable() { public void run() { try { // Ready to go! ioReactor.execute(ioEventDispatch); } catch (InterruptedIOException ex) { System.err.println(&quot;Interrupted&quot;); } catch (IOException e) { System.err.println(&quot;I/O error: &quot; + e.getMessage()); } System.out.println(&quot;Shutdown&quot;); }});// Start the client threadt.start();// Create HTTP requesterHttpAsyncRequester requester = new HttpAsyncRequester(httpproc);// Execute HTTP GETs to the following hosts andHttpHost[] targets = new HttpHost[] {new HttpHost(&quot;shuvigoss.win&quot;, 80, &quot;http&quot;), new HttpHost(&quot;shuvigoss.win&quot;, 80, &quot;http&quot;), new HttpHost(&quot;shuvigoss.win&quot;, 80, &quot;http&quot;)};final CountDownLatch latch = new CountDownLatch(targets.length);for (final HttpHost target : targets) { BasicHttpRequest request = new BasicHttpRequest(&quot;GET&quot;, &quot;/&quot;); HttpCoreContext coreContext = HttpCoreContext.create(); requester.execute(new BasicAsyncRequestProducer(target, request), new BasicAsyncResponseConsumer(), pool, coreContext, // Handle HTTP response from a callback new FutureCallback&lt;HttpResponse&gt;() { public void completed(final HttpResponse response) { latch.countDown(); System.out.println(target + &quot;-&gt;&quot; + response.getStatusLine()); } public void failed(final Exception ex) { latch.countDown(); System.out.println(target + &quot;-&gt;&quot; + ex); } public void cancelled() { latch.countDown(); System.out.println(target + &quot; cancelled&quot;); } });}latch.await();System.out.println(&quot;Shutting down I/O reactor&quot;);ioReactor.shutdown();System.out.println(&quot;Done&quot;); 上图是对NIO Reactor各角色的划分,其中MainReactor运行于线程1,其他SubReactor根据CPU数量运行于其他线程.其中MainReactor主要负责处理SelectionKey.OP_CONNECT.SubReactor负责SelectionKey.OP_READ、SelectionKey.OP_WRITE. MainReactor IOReactor execute(IOEventDispatch eventDispatch)1234567891011121314151617Thread t = new Thread(new Runnable() { public void run() { try { // Ready to go! ioReactor.execute(ioEventDispatch); } catch (InterruptedIOException ex) { System.err.println(&quot;Interrupted&quot;); } catch (IOException e) { System.err.println(&quot;I/O error: &quot; + e.getMessage()); } System.out.println(&quot;Shutdown&quot;); }});// Start the client threadt.start(); 这里就已经启动了MainReactor Loop. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public void execute( final IOEventDispatch eventDispatch) throws InterruptedIOException, IOReactorException { Args.notNull(eventDispatch, &quot;Event dispatcher&quot;); synchronized (this.statusLock) { if (this.status.compareTo(IOReactorStatus.SHUTDOWN_REQUEST) &gt;= 0) { this.status = IOReactorStatus.SHUT_DOWN; this.statusLock.notifyAll(); return; } Asserts.check(this.status.compareTo(IOReactorStatus.INACTIVE) == 0, &quot;Illegal state %s&quot;, this.status); this.status = IOReactorStatus.ACTIVE; // Start I/O dispatchers // 创建SubReactor,数量默认为CPU数量,并且运行在Worker线程上 for (int i = 0; i &lt; this.dispatchers.length; i++) { final BaseIOReactor dispatcher = new BaseIOReactor(this.selectTimeout, this.interestOpsQueueing); dispatcher.setExceptionHandler(exceptionHandler); this.dispatchers[i] = dispatcher; } for (int i = 0; i &lt; this.workerCount; i++) { final BaseIOReactor dispatcher = this.dispatchers[i]; this.workers[i] = new Worker(dispatcher, eventDispatch); this.threads[i] = this.threadFactory.newThread(this.workers[i]); } } try { for (int i = 0; i &lt; this.workerCount; i++) { if (this.status != IOReactorStatus.ACTIVE) { return; } this.threads[i].start(); } for (;;) { final int readyCount; try { //获取连接Key事件 SelectionKey.OP_CONNECT readyCount = this.selector.select(this.selectTimeout); } catch (final InterruptedIOException ex) { throw ex; } catch (final IOException ex) { throw new IOReactorException(&quot;Unexpected selector failure&quot;, ex); } if (this.status.compareTo(IOReactorStatus.ACTIVE) == 0) { //处理连接 processEvents(readyCount); } // Verify I/O dispatchers for (int i = 0; i &lt; this.workerCount; i++) { final Worker worker = this.workers[i]; final Exception ex = worker.getException(); if (ex != null) { throw new IOReactorException( &quot;I/O dispatch worker terminated abnormally&quot;, ex); } } if (this.status.compareTo(IOReactorStatus.ACTIVE) &gt; 0) { break; } } } catch (final ClosedSelectorException ex) { addExceptionEvent(ex); } catch (final IOReactorException ex) { if (ex.getCause() != null) { addExceptionEvent(ex.getCause()); } throw ex; } finally { doShutdown(); synchronized (this.statusLock) { this.status = IOReactorStatus.SHUT_DOWN; this.statusLock.notifyAll(); } }} 上面的代码其实逻辑很简单. 创建SubReactor(Worker Thread)并且运行. 监听Connect事件,并且处理 这里有个疑问,并没有给这个selector注册过OP_CONNECT,这块比较巧妙,后边会介绍. HttpAsyncRequester execute下面是创建Request并且由HttpAsyncRequester执行 12345678910111213141516171819202122232425for (final HttpHost target : targets) { BasicHttpRequest request = new BasicHttpRequest(&quot;GET&quot;, &quot;/&quot;); HttpCoreContext coreContext = HttpCoreContext.create(); requester.execute(new BasicAsyncRequestProducer(target, request), new BasicAsyncResponseConsumer(), pool, coreContext, // Handle HTTP response from a callback new FutureCallback&lt;HttpResponse&gt;() { public void completed(final HttpResponse response) { latch.countDown(); System.out.println(target + &quot;-&gt;&quot; + response.getStatusLine()); } public void failed(final Exception ex) { latch.countDown(); System.out.println(target + &quot;-&gt;&quot; + ex); } public void cancelled() { latch.countDown(); System.out.println(target + &quot; cancelled&quot;); } });} 通过连接池,创建Request. 1234567891011121314151617181920212223242526public Future&lt;E&gt; lease( final T route, final Object state, final long connectTimeout, final long leaseTimeout, final TimeUnit tunit, final FutureCallback&lt;E&gt; callback) { Args.notNull(route, &quot;Route&quot;); Args.notNull(tunit, &quot;Time unit&quot;); Asserts.check(!this.isShutDown.get(), &quot;Connection pool shut down&quot;); final BasicFuture&lt;E&gt; future = new BasicFuture&lt;E&gt;(callback); this.lock.lock(); try { final long timeout = connectTimeout &gt; 0 ? tunit.toMillis(connectTimeout) : 0; final LeaseRequest&lt;T, C, E&gt; request = new LeaseRequest&lt;T, C, E&gt;(route, state, timeout, leaseTimeout, future); final boolean completed = processPendingRequest(request); if (!request.isDone() &amp;&amp; !completed) { this.leasingRequests.add(request); } if (request.isDone()) { this.completedRequests.add(request); } } finally { this.lock.unlock(); } fireCallbacks(); return future; } 这里边的processPendingRequest(request)很重要,里边代码量有点大,我把主要的核心代码贴出来分析. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// New connection is neededfinal int maxPerRoute = getMax(route);// Shrink the pool prior to allocating a new connectionfinal int excess = Math.max(0, pool.getAllocatedCount() + 1 - maxPerRoute);if (excess &gt; 0) { for (int i = 0; i &lt; excess; i++) { final E lastUsed = pool.getLastUsed(); if (lastUsed == null) { break; } lastUsed.close(); this.available.remove(lastUsed); pool.remove(lastUsed); }}if (pool.getAllocatedCount() &lt; maxPerRoute) { final int totalUsed = this.pending.size() + this.leased.size(); final int freeCapacity = Math.max(this.maxTotal - totalUsed, 0); if (freeCapacity == 0) { return false; } final int totalAvailable = this.available.size(); if (totalAvailable &gt; freeCapacity - 1) { if (!this.available.isEmpty()) { final E lastUsed = this.available.removeLast(); lastUsed.close(); final RouteSpecificPool&lt;T, C, E&gt; otherpool = getPool(lastUsed.getRoute()); otherpool.remove(lastUsed); } } final SocketAddress localAddress; final SocketAddress remoteAddress; try { remoteAddress = this.addressResolver.resolveRemoteAddress(route); localAddress = this.addressResolver.resolveLocalAddress(route); } catch (final IOException ex) { request.failed(ex); return false; } //调用ioreactor(DefaultConnectingIOReactor) 进行connect final SessionRequest sessionRequest = this.ioreactor.connect( remoteAddress, localAddress, route, this.sessionRequestCallback); final int timout = request.getConnectTimeout() &lt; Integer.MAX_VALUE ? (int) request.getConnectTimeout() : Integer.MAX_VALUE; sessionRequest.setConnectTimeout(timout); this.pending.add(sessionRequest); pool.addPending(sessionRequest, request.getFuture()); return true;} else { return false;} 这段代码很重要this.ioreactor.connect,实际上调用的是DefaultConnectingIOReactor.connect方法. 接下来就是注册CONNET事件的核心代码了. 1234567891011121314151617@Overridepublic SessionRequest connect( final SocketAddress remoteAddress, final SocketAddress localAddress, final Object attachment, final SessionRequestCallback callback) { Asserts.check(this.status.compareTo(IOReactorStatus.ACTIVE) &lt;= 0, &quot;I/O reactor has been shut down&quot;); final SessionRequestImpl sessionRequest = new SessionRequestImpl( remoteAddress, localAddress, attachment, callback); sessionRequest.setConnectTimeout(this.config.getConnectTimeout()); this.requestQueue.add(sessionRequest); this.selector.wakeup(); return sessionRequest;} 创建一个SessionRequest并放入DefaultConnectingIOReactor.requestQueue内. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private void processSessionRequests() throws IOReactorException { SessionRequestImpl request; while ((request = this.requestQueue.poll()) != null) { if (request.isCompleted()) { continue; } final SocketChannel socketChannel; try { socketChannel = SocketChannel.open(); } catch (final IOException ex) { request.failed(ex); return; } try { validateAddress(request.getLocalAddress()); validateAddress(request.getRemoteAddress()); socketChannel.configureBlocking(false); prepareSocket(socketChannel.socket()); if (request.getLocalAddress() != null) { final Socket sock = socketChannel.socket(); sock.setReuseAddress(this.config.isSoReuseAddress()); sock.bind(request.getLocalAddress()); } final boolean connected = socketChannel.connect(request.getRemoteAddress()); if (connected) { final ChannelEntry entry = new ChannelEntry(socketChannel, request); addChannel(entry); continue; } } catch (final IOException ex) { closeChannel(socketChannel); request.failed(ex); return; } final SessionRequestHandle requestHandle = new SessionRequestHandle(request); try { final SelectionKey key = socketChannel.register(this.selector, SelectionKey.OP_CONNECT, requestHandle); request.setKey(key); } catch (final IOException ex) { closeChannel(socketChannel); throw new IOReactorException(&quot;Failure registering channel &quot; + &quot;with the selector&quot;, ex); } }} processSessionRequests循环获取requestQueue,如果有元素将会创建一个Channel并且注册SelectionKey.OP_CONNECT到selector 最后,处理连接finishConnect,将新的Channel加到SubReactor内. 123456789101112131415161718192021222324252627282930313233343536373839private void processEvent(final SelectionKey key) { try { if (key.isConnectable()) { final SocketChannel channel = (SocketChannel) key.channel(); // Get request handle final SessionRequestHandle requestHandle = (SessionRequestHandle) key.attachment(); final SessionRequestImpl sessionRequest = requestHandle.getSessionRequest(); // Finish connection process try { channel.finishConnect(); } catch (final IOException ex) { sessionRequest.failed(ex); } key.cancel(); key.attach(null); if (!sessionRequest.isCompleted()) { addChannel(new ChannelEntry(channel, sessionRequest)); } else { try { channel.close(); } catch (IOException ignore) { } } } } catch (final CancelledKeyException ex) { final SessionRequestHandle requestHandle = (SessionRequestHandle) key.attachment(); key.attach(null); if (requestHandle != null) { final SessionRequestImpl sessionRequest = requestHandle.getSessionRequest(); if (sessionRequest != null) { sessionRequest.cancel(); } } }} 尽量平均的分配到SubReactor 12345protected void addChannel(final ChannelEntry entry) { // Distribute new channels among the workers final int i = Math.abs(this.currentWorker++ % this.workerCount); this.dispatchers[i].addChannel(entry);} 到此连接创建的核心代码就读完了,稍微有那么一点点的绕. SubReactor IOReactor execute(IOEventDispatch eventDispatch)这里的SubReactor具体实现为BaseIOReactor 1234567@Overridepublic void execute( final IOEventDispatch eventDispatch) throws InterruptedIOException, IOReactorException { Args.notNull(eventDispatch, &quot;Event dispatcher&quot;); this.eventDispatch = eventDispatch; execute();} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364protected void execute() throws InterruptedIOException, IOReactorException { this.status = IOReactorStatus.ACTIVE; try { for (;;) { final int readyCount; try { readyCount = this.selector.select(this.selectTimeout); } catch (final InterruptedIOException ex) { throw ex; } catch (final IOException ex) { throw new IOReactorException(&quot;Unexpected selector failure&quot;, ex); } if (this.status == IOReactorStatus.SHUT_DOWN) { // Hard shut down. Exit select loop immediately break; } if (this.status == IOReactorStatus.SHUTTING_DOWN) { // Graceful shutdown in process // Try to close things out nicely closeSessions(); closeNewChannels(); } // Process selected I/O events if (readyCount &gt; 0) { processEvents(this.selector.selectedKeys()); } // Validate active channels validate(this.selector.keys()); // Process closed sessions processClosedSessions(); // If active process new channels if (this.status == IOReactorStatus.ACTIVE) { processNewChannels(); } // Exit select loop if graceful shutdown has been completed if (this.status.compareTo(IOReactorStatus.ACTIVE) &gt; 0 &amp;&amp; this.sessions.isEmpty()) { break; } if (this.interestOpsQueueing) { // process all pending interestOps() operations processPendingInterestOps(); } } } catch (final ClosedSelectorException ignore) { } finally { hardShutdown(); synchronized (this.statusMutex) { this.statusMutex.notifyAll(); } }} SubReactor具体处理2个比较重要的事情 processEvents(this.selector.selectedKeys()); 处理具体读写事件 processNewChannels(); 处理新的Channel 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374private void processNewChannels() throws IOReactorException { ChannelEntry entry; while ((entry = this.newChannels.poll()) != null) { final SocketChannel channel; final SelectionKey key; try { channel = entry.getChannel(); channel.configureBlocking(false); key = channel.register(this.selector, SelectionKey.OP_READ); } catch (final ClosedChannelException ex) { final SessionRequestImpl sessionRequest = entry.getSessionRequest(); if (sessionRequest != null) { sessionRequest.failed(ex); } return; } catch (final IOException ex) { throw new IOReactorException(&quot;Failure registering channel &quot; + &quot;with the selector&quot;, ex); } final SessionClosedCallback sessionClosedCallback = new SessionClosedCallback() { @Override public void sessionClosed(final IOSession session) { queueClosedSession(session); } }; InterestOpsCallback interestOpsCallback = null; if (this.interestOpsQueueing) { interestOpsCallback = new InterestOpsCallback() { @Override public void addInterestOps(final InterestOpEntry entry) { queueInterestOps(entry); } }; } final IOSession session; try { session = new IOSessionImpl(key, interestOpsCallback, sessionClosedCallback); int timeout = 0; try { timeout = channel.socket().getSoTimeout(); } catch (final IOException ex) { // Very unlikely to happen and is not fatal // as the protocol layer is expected to overwrite // this value anyways } session.setAttribute(IOSession.ATTACHMENT_KEY, entry.getAttachment()); session.setSocketTimeout(timeout); } catch (final CancelledKeyException ex) { continue; } try { this.sessions.add(session); final SessionRequestImpl sessionRequest = entry.getSessionRequest(); if (sessionRequest != null) { sessionRequest.completed(session); } key.attach(session); sessionCreated(key, session); } catch (final CancelledKeyException ex) { queueClosedSession(session); key.attach(null); } }} 处理新的Channel逻辑也比较简单 首先注册SelectionKey.OP_READ 然后创建IOSessionattach到Key上,从IOSession接口上看到,它主要负责对于事件的派发 sessionCreated(key, session)会调用DefaultHttpClientIODispatch.onConnected方法.这个分发器会调用HttpAsyncRequestExecutor(handler)来做具体连接后的事情. HttpAsyncRequestExecutor就是真正用于处理请求发送以及返回解析的处理类. 12345678910@Overrideprotected void sessionCreated(final SelectionKey key, final IOSession session) { try { this.eventDispatch.connected(session); } catch (final CancelledKeyException ex) { queueClosedSession(session); } catch (final RuntimeException ex) { handleRuntimeException(ex); }} 1234567891011121314151617181920212223242526272829@Overridepublic void connected(final IOSession session) { @SuppressWarnings(&quot;unchecked&quot;) T conn = (T) session.getAttribute(IOEventDispatch.CONNECTION_KEY); try { if (conn == null) { conn = createConnection(session); session.setAttribute(IOEventDispatch.CONNECTION_KEY, conn); } onConnected(conn); final SSLIOSession ssliosession = (SSLIOSession) session.getAttribute( SSLIOSession.SESSION_KEY); if (ssliosession != null) { try { synchronized (ssliosession) { if (!ssliosession.isInitialized()) { ssliosession.initialize(); } } } catch (final IOException ex) { onException(conn, ex); ssliosession.shutdown(); } } } catch (final RuntimeException ex) { session.shutdown(); throw ex; }} 123456789@Overrideprotected void onConnected(final DefaultNHttpClientConnection conn) { final Object attachment = conn.getContext().getAttribute(IOSession.ATTACHMENT_KEY); try { this.handler.connected(conn, attachment); } catch (final Exception ex) { this.handler.exception(conn, ex); }} 123456789@Overridepublic void connected( final NHttpClientConnection conn, final Object attachment) throws IOException, HttpException { final State state = new State(); final HttpContext context = conn.getContext(); context.setAttribute(HTTP_EXCHANGE_STATE, state); requestReady(conn);} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@Overridepublic void requestReady( final NHttpClientConnection conn) throws IOException, HttpException { final State state = getState(conn); Asserts.notNull(state, &quot;Connection state&quot;); Asserts.check(state.getRequestState() == MessageState.READY || state.getRequestState() == MessageState.COMPLETED, &quot;Unexpected request state %s&quot;, state.getRequestState()); if (state.getRequestState() == MessageState.COMPLETED) { conn.suspendOutput(); return; } final HttpContext context = conn.getContext(); final HttpAsyncClientExchangeHandler handler; synchronized (context) { handler = getHandler(conn); if (handler == null || handler.isDone()) { conn.suspendOutput(); return; } } final boolean pipelined = handler.getClass().getAnnotation(Pipelined.class) != null; final HttpRequest request = handler.generateRequest(); if (request == null) { conn.suspendOutput(); return; } final ProtocolVersion version = request.getRequestLine().getProtocolVersion(); if (pipelined &amp;&amp; version.lessEquals(HttpVersion.HTTP_1_0)) { throw new ProtocolException(version + &quot; cannot be used with request pipelining&quot;); } state.setRequest(request); if (pipelined) { state.getRequestQueue().add(request); } if (request instanceof HttpEntityEnclosingRequest) { final boolean expectContinue = ((HttpEntityEnclosingRequest) request).expectContinue(); if (expectContinue &amp;&amp; pipelined) { throw new ProtocolException(&quot;Expect-continue handshake cannot be used with request pipelining&quot;); } conn.submitRequest(request); if (expectContinue) { final int timeout = conn.getSocketTimeout(); state.setTimeout(timeout); conn.setSocketTimeout(this.waitForContinue); state.setRequestState(MessageState.ACK_EXPECTED); } else { final HttpEntity entity = ((HttpEntityEnclosingRequest) request).getEntity(); if (entity != null) { state.setRequestState(MessageState.BODY_STREAM); } else { handler.requestCompleted(); state.setRequestState(pipelined ? MessageState.READY : MessageState.COMPLETED); } } } else { conn.submitRequest(request);//会通过IOSession注册OP_WRITE事件 handler.requestCompleted(); state.setRequestState(pipelined ? MessageState.READY : MessageState.COMPLETED); }} 这里conn.submitRequest(request);会注册OP_WRITE到selector. ending这里框架上的东西差不多就完了,总结一下. DefaultConnectingIOReactor 负责处理所有连接,创建Channel并将Channel分配到SubReactor(BaseIOReactor) HttpAsyncRequestExecutor作用是Handler,处理所有连接创建、读、写等等 DefaultHttpClientIODispatch 主要用于派发具体的事件 BaseIOReactor负责读写事件的处理 其实还有很多细节实在没法写了,具体还是从代码层面看！","link":"/2016/09/23/%E3%80%90HttpComponents%E3%80%91%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%902-HttpCore&nio/"},{"title":"【Zookeeper】Curator-分布式读写锁的实现","text":"【Zookeeper】Curator-分布式锁的实现介绍了`Curator`如何实现的mutex,那么它也有读写锁的实现,废话不多说,先看它的设计. 那么它做了以下的改造完成了读写锁实现. 读锁节点为uuid__READ__sequence,写锁为uuid__WRIT__sequence 读锁、写锁分别是一个InterProcessMutex的子类 是否可读判断依据为排序后的节点,从当前线程写入节点的所有前置节点中没有__WRIT__的节点 是否可写的判断依据当前线程节点前没有其他__WRIT__节点 下面针对代码来快速的看一遍. Common123// must be the same length. LockInternals depends on itprivate static final String READ_LOCK_NAME = &quot;__READ__&quot;;private static final String WRITE_LOCK_NAME = &quot;__WRIT__&quot;; 定义了读写锁节点Path中段标识. 12345678910111213141516171819202122232425262728293031323334353637private static class InternalInterProcessMutex extends InterProcessMutex{ private final String lockName; private final byte[] lockData; InternalInterProcessMutex(CuratorFramework client, String path, String lockName, byte[] lockData, int maxLeases, LockInternalsDriver driver) { super(client, path, lockName, maxLeases, driver); this.lockName = lockName; this.lockData = lockData; } @Override public Collection&lt;String&gt; getParticipantNodes() throws Exception { Collection&lt;String&gt; nodes = super.getParticipantNodes(); Iterable&lt;String&gt; filtered = Iterables.filter ( nodes, new Predicate&lt;String&gt;() { @Override public boolean apply(String node) { return node.contains(lockName); } } ); return ImmutableList.copyOf(filtered); } @Override protected byte[] getLockNodeBytes() { return lockData; }} 创建了InterProcessMutex的一个子类,对读写锁进行了一个抽象,重写了getParticipantNodes()方法使其返回相同类型的节点数据,判断依据就是节点中是否包含相应锁的中段标识. writeLock12345678910111213141516writeMutex = new InternalInterProcessMutex( client, basePath, WRITE_LOCK_NAME, lockData, 1, new SortingLockInternalsDriver() { @Override public PredicateResults getsTheLock(CuratorFramework client, List&lt;String&gt; children, String sequenceNodeName, int maxLeases) throws Exception { return super.getsTheLock(client, children, sequenceNodeName, maxLeases); } }); writeLock就是一个InterProcessMutex,也就是独占锁,writeLock写的节点前没有其他writeLock,那就是获得锁. readLock12345678910111213141516readMutex = new InternalInterProcessMutex( client, basePath, READ_LOCK_NAME, lockData, Integer.MAX_VALUE, new SortingLockInternalsDriver() { @Override public PredicateResults getsTheLock(CuratorFramework client, List&lt;String&gt; children, String sequenceNodeName, int maxLeases) throws Exception { return readLockPredicate(children, sequenceNodeName); } }); readLock稍微有所不同,readLock是一个共享锁,在构造InternalInterProcessMutex上传入了一个Integer.MAX_VALUE值,也就是说只要节点中的read节点不超过Integer.MAX_VALUE那么都可以获得锁(前提是没有write锁). 1234567891011121314151617181920212223242526272829303132333435private PredicateResults readLockPredicate(List&lt;String&gt; children, String sequenceNodeName) throws Exception{ //写锁到读锁的降级处理,如果当前线程获得了写锁那么它同时也可以直接 //降级为读锁 if ( writeMutex.isOwnedByCurrentThread() ) { return new PredicateResults(null, true); } //找到当前节点前是否有写锁. int index = 0; int firstWriteIndex = Integer.MAX_VALUE; int ourIndex = -1; for ( String node : children ) { if ( node.contains(WRITE_LOCK_NAME) ) { firstWriteIndex = Math.min(index, firstWriteIndex); } else if ( node.startsWith(sequenceNodeName) ) { ourIndex = index; break; } ++index; } StandardLockInternalsDriver.validateOurIndex(sequenceNodeName, ourIndex); //如果当前节点的index小于第一个写锁的index 那么getsTheLock=true,否则就是false. boolean getsTheLock = (ourIndex &lt; firstWriteIndex); //所有未获得读锁的读节点会去watch第一个写锁,等待写锁释放并重新执行获取锁的流程. String pathToWatch = getsTheLock ? null : children.get(firstWriteIndex); return new PredicateResults(pathToWatch, getsTheLock);} 总结Curator读写锁实现比较简单而且巧妙,使用起来注意以下几点. 写锁可以降级为读锁,但是读锁不能升级为写锁. 读写锁都可重入,但在有写锁的时候,读锁是不可进行重入的,直到写锁释放后才可以重入. 写锁是公平锁.","link":"/2017/03/15/%E3%80%90Zookeeper%E3%80%91Curator-%E5%88%86%E5%B8%83%E5%BC%8F%E8%AF%BB%E5%86%99%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"title":"【Zookeeper】Curator-分布式锁的实现","text":"CuratorFramework提供了对于Zookeeperclient的封装,使调用者能够更方便的使用Zookeeper,同时也提供了很多菜谱(recipes),其中的分布式锁是最常用的,那它是怎么基于Zookeeper实现的分布式锁呢? simple由于很多关于Zookeeper分布式锁的实现上都采用创建同一节点,成功则获得锁,失败则等待并且监听这个节点。 这种方式很像Java中的synchronized关键字,每一次获得锁都是竞争的关系.我大致画了一下这种方式的实现思路. 实现这里就不写了,大部分的实现都是这个思路. Curator InterProcessMutex这里着重讲一下Curator的实现:InterProcessMutex,首先看一下设计思路. 它的实现思路比较特别 生成以 “lock-“ + uuid + sequence 的EPHEMERAL_SEQUENTIAL节点. 查询所有lockPath下的节点. 如果查询到当前线程创建的 uuid 节点,表明当前线程已经获得锁或者在锁的等待队列中.如果没有查询到,说明当前Zookeeper节点并未同步完数据,跳转到2. 对查询所有节点的List进行筛选,如果自己创建的节点并不是List的第0个元素,说明自己未获得锁,那么进行等待并且设置Watcher观察自己的前置节点,如果Watcher被调用,返回2重新执行.如果自己创建的节点等于List第0个元素,说明已经获取锁,返回true. 这样做的方式很像Java中的ReentrantLock,有一个等待队列,保证了线程获取锁的顺序,并且支持重入,但它只有公平锁特性. 在我刚读代码的时候有一个疑虑,就是如果你当前线程(进程)创建的自己的临时节点， 在获取的时候怎么可能获取不到自己创建的节点呢?这块是由于我当时对Zookeeper 的ZAB协议理解并不深.在Leader收到Transcation的proposal时,会以原子广播 的形式发给所有Follower,它认为集群中超过半数+1节点返回成功那么就是成功, 那么这就存在一个问题就是不在这半数+1节点的集群中数据在这个时间点上会存在 暂时的不一致情况,依赖后面的同步数据来保证数据最终的一致性.所以说Zookeeper 的一致性是最终一致性. acquire Lock下面来看代码实现. 1234567InterProcessMutex lock = new InterProcessMutex(client, &quot;/mutex&quot;);try { lock.acquire(); System.out.println(&quot;i got lock&quot;);} catch (Exception e) { e.printStackTrace();} 在构造函数里会指定需要加锁的Path,所有加锁线程会在这个Path下创建临时有序节点. 123//这个lock-前缀是为了区分这个是一个锁标示,有可能在指定节点路径下会有其他节点.//这个是在获取锁节点时的一个过滤条件,非以lock-开头的节点会被认为是无用节点.private static final String LOCK_NAME = &quot;lock-&quot;; 1234567891011121314@Overridepublic void acquire() throws Exception{ if ( !internalLock(-1, null) ) { throw new IOException(&quot;Lost connection while trying to acquire lock: &quot; + basePath); }}@Overridepublic boolean acquire(long time, TimeUnit unit) throws Exception{ return internalLock(time, unit);} 这2个方法是获取锁的入口方法,提供了超时等待的功能. 12345678910111213141516171819202122232425262728private boolean internalLock(long time, TimeUnit unit) throws Exception{ /* Note on concurrency: a given lockData instance can be only acted on by a single thread so locking isn't necessary */ Thread currentThread = Thread.currentThread(); //获取当前缓存中是已经获取过锁,这是重入的一个实现,如果已经获取锁, //那么对lockCount进行++ LockData lockData = threadData.get(currentThread); if ( lockData != null ) { // re-entering lockData.lockCount.incrementAndGet(); return true; } //尝试获取锁,如果获得锁,会将线程信息存入threadData并返回true String lockPath = internals.attemptLock(time, unit, getLockNodeBytes()); if ( lockPath != null ) { LockData newLockData = new LockData(currentThread, lockPath); threadData.put(currentThread, newLockData); return true; } return false;} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546String attemptLock(long time, TimeUnit unit, byte[] lockNodeBytes) throws Exception{ //设置一些本地变量,后边依据这些变量进行超时判断,是否获取锁等等. final long startMillis = System.currentTimeMillis(); final Long millisToWait = (unit != null) ? unit.toMillis(time) : null; final byte[] localLockNodeBytes = (revocable.get() != null) ? new byte[0] : lockNodeBytes; int retryCount = 0; String ourPath = null; boolean hasTheLock = false; boolean isDone = false; while ( !isDone ) { isDone = true; try { //开始创建节点 ourPath = driver.createsTheLock(client, path, localLockNodeBytes); //根据创建节点进行过滤并且判断是否是第0个元素 hasTheLock = internalLockLoop(startMillis, millisToWait, ourPath); } catch ( KeeperException.NoNodeException e ) { // gets thrown by StandardLockInternalsDriver when it can't find the lock node // this can happen when the session expires, etc. So, if the retry allows, just try it all again // 重试,这块在internalLockLoop内部判断ourPath是否存在children List内时会 // 抛出NoNodeException,这就是解决某一节点同步延迟的情况 if ( client.getZookeeperClient().getRetryPolicy().allowRetry(retryCount++, System.currentTimeMillis() - startMillis, RetryLoop.getDefaultRetrySleeper()) ) { isDone = false; } else { throw e; } } } if ( hasTheLock ) { return ourPath; } return null;} 1234567891011121314@Overridepublic String createsTheLock(CuratorFramework client, String path, byte[] lockNodeBytes) throws Exception{ String ourPath; if ( lockNodeBytes != null ) { ourPath = client.create().creatingParentContainersIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path, lockNodeBytes); } else { ourPath = client.create().creatingParentContainersIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path); } return ourPath;} createsTheLock就是创建一个临时有序节点,其中的withProtection()方法就是创建带有uuid的节点方法,为什么会有这种需求呢?我读了下ProtectACLCreateModePathAndBytesable的介绍,这是一种设计上的优化,针对创建一个SEQUENTIAL节点,客户端并不能知道你创建的节点到底是什么path,有了这种GUID的设计能够在不查询节点内容的情况下知道自己创建的有序节点是哪个. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879private boolean internalLockLoop(long startMillis, Long millisToWait, String ourPath) throws Exception{ boolean haveTheLock = false; boolean doDelete = false; try { //这是锁撤销的一个扩展,如果设置了可撤销,那么在需要的时候进行锁节点变更, //将节点内容写为&quot;__REVOKE__&quot;就可实现锁撤销 if ( revocable.get() != null ) { client.getData().usingWatcher(revocableWatcher).forPath(ourPath); } while ( (client.getState() == CuratorFrameworkState.STARTED) &amp;&amp; !haveTheLock ) { //获取Path下所有节点,进行排序和过滤,这里返回的是一个所有锁节点的排序结果 List&lt;String&gt; children = getSortedChildren(); //获得自己锁的uuid String sequenceNodeName = ourPath.substring(basePath.length() + 1); // +1 to include the slash //判断是否获得锁并且需要Watcher的节点名称(也就是前置节点) PredicateResults predicateResults = driver.getsTheLock(client, children, sequenceNodeName, maxLeases); //获得锁,即将返回 if ( predicateResults.getsTheLock() ) { haveTheLock = true; } else { //未获得锁,在等待时间内观察前置节点, //唤醒的条件是前置节点变更或者等待时间到 String previousSequencePath = basePath + &quot;/&quot; + predicateResults.getPathToWatch(); synchronized(this) { try { // use getData() instead of exists() to avoid leaving unneeded watchers which is a type of resource leak client.getData().usingWatcher(watcher).forPath(previousSequencePath); if ( millisToWait != null ) { millisToWait -= (System.currentTimeMillis() - startMillis); startMillis = System.currentTimeMillis(); if ( millisToWait &lt;= 0 ) { doDelete = true; // timed out - delete our node break; } wait(millisToWait); } else { wait(); } } catch ( KeeperException.NoNodeException e ) { // it has been deleted (i.e. lock released). Try to acquire again } } } } } catch ( Exception e ) { ThreadUtils.checkInterrupted(e); doDelete = true; throw e; } finally { //清理需要删除节点,如果线程被中段或者线程等待时间超时 if ( doDelete ) { deleteOurPath(ourPath); } } return haveTheLock;} 12345678private final Watcher watcher = new Watcher(){ @Override public void process(WatchedEvent event) { notifyFromWatcher(); }}; 在internalLockLoop方法执行时,未获得锁的线程会wait,直到观察的前置节点发生变动并唤醒. 以上就是获取锁的源码分析 release Lock释放锁的代码很简单,需要关注一下重入的情况即可. 1234567891011121314151617181920212223242526272829303132333435363738@Overridepublic void release() throws Exception{ /* Note on concurrency: a given lockData instance can be only acted on by a single thread so locking isn't necessary */ Thread currentThread = Thread.currentThread(); LockData lockData = threadData.get(currentThread); //并未获得过锁 if ( lockData == null ) { throw new IllegalMonitorStateException(&quot;You do not own the lock: &quot; + basePath); } //lockCount-1 int newLockCount = lockData.lockCount.decrementAndGet(); //如果-1后的结果依然大于0,说明是重入的情况,所以直接返回等待最后一个release if ( newLockCount &gt; 0 ) { return; } //已经释放过锁或者其他的情况 if ( newLockCount &lt; 0 ) { throw new IllegalMonitorStateException(&quot;Lock count has gone negative for lock: &quot; + basePath); } try { //释放锁 internals.releaseLock(lockData.lockPath); } finally { //从threadData中将当前线程remove threadData.remove(currentThread); }} 1234567void releaseLock(String lockPath) throws Exception{ //设置撤销标识为空 revocable.set(null); //删除锁节点 deleteOurPath(lockPath);} 需要注意acquire与release是成对出现的,否则会出现死锁的情况 扩展InterProcessMutex这个类其实是一个基础类,里边提供了很多的扩展,比如它有一个package内可见的构造方法,可以提供一个maxLeases的扩展,后边读写锁的分析就使用到了这个扩展点. 12345InterProcessMutex(CuratorFramework client, String path, String lockName, int maxLeases, LockInternalsDriver driver){ basePath = PathUtils.validatePath(path); internals = new LockInternals(client, driver, path, lockName, maxLeases);} 以上就是Curator对于分布式锁的实现,思路比较清晰,代码也比较好懂.","link":"/2017/03/10/%E3%80%90Zookeeper%E3%80%91Curator-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"title":"Git系列-3-hello world","text":"创建仓库init123456$ mkdir learngit$ cd learngit$ git initInitialized empty Git repository in /Users/shuvigoss/gitrepository/learngit/.git/ Git仓库已经创建好了，我们看下文件夹里边都有什么内容。 123456789101112131415$ ls -alldrwxr-xr-x 10 shuvigoss staff 340B Aug 25 15:19 .git$ cd .git/$ ls -all-rw-r--r-- 1 shuvigoss staff 23 Aug 25 15:18 HEADdrwxr-xr-x 2 shuvigoss staff 68 Aug 25 15:18 branches-rw-r--r-- 1 shuvigoss staff 137 Aug 25 15:18 config-rw-r--r-- 1 shuvigoss staff 73 Aug 25 15:18 descriptiondrwxr-xr-x 11 shuvigoss staff 374 Aug 25 15:18 hooksdrwxr-xr-x 3 shuvigoss staff 102 Aug 25 15:18 infodrwxr-xr-x 4 shuvigoss staff 136 Aug 25 15:18 objectsdrwxr-xr-x 4 shuvigoss staff 136 Aug 25 15:18 refs 先看一下里边的内容，这些构成了这个仓库所有功能，包括版本、头指针、config等等，这里可以先不管，如果有时间可以详细看看 add &amp; commit &amp; status123456789101112$ echo &quot;first blood&quot; &gt; README.md$ git statusOn branch masterInitial commitUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) README.mdnothing added to commit but untracked files present (use &quot;git add&quot; to track) 12345678910$ git add README.md$ git statusOn branch masterInitial commitChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: README.md 12345678$ git commit -m 'first commit'[master (root-commit) 3d78e6b] first commit 1 file changed, 1 insertion(+) create mode 100644 README.md$ git statusOn branch masternothing to commit, working directory clean 通过add commit 可以实现网仓库提交修改。 Note：在提交时一定要加 -m 参数并且写上你提交内容的注释 比如在一次提交中你增加了个功能A，半年后你想看当时增加的功能A有哪些改动，通过注释就可以很直白的知道。 status 命令可以查看当前工作区的状态，是一个非常重要的命令。 add 命令不要被他的字面意思迷惑，他的意思是add modify而不是单纯的增加文件。从下面的例子就能很直白的明白了。 123456789101112131415161718192021222324252627282930$ echo &quot;second blood&quot; &gt;&gt; README.md$ more README.mdfirst bloodsecond blood$ git statusOn branch masterChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: README.mdno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)$ git add *.md $ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: README.md$ git commit -m 'second commit'[master afef6dd] second commit 1 file changed, 1 insertion(+)$ git statusOn branch masternothing to commit, working directory clean 其中add命令可以使用类似add *.txt这种模糊匹配、add a.txt b.txt多文件、add -A等多种形式。 resetreset命令是回退命令，功能很多。 1234567891011121314$ touch a.txt$ git add a.txt$ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: a.txt$ git reset HEAD a.txt$ rm -rf a.txt$ git statusOn branch masternothing to commit, working directory clean (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) 在add之后，它会提示你使用reset可以进行add 的撤销 diffdiff命令用户比较difference，使用的是Unix通用的diff格式 12$ echo &quot;third blood&quot; &gt;&gt; README.md$ git diff README.md 12345678diff --git a/README.md b/README.mdindex 09cd50b..6ffccbe 100644--- a/README.md+++ b/README.md@@ -1,2 +1,3 @@ first blood second blood+third blood 可以看到文件变化了，在文本最后增加了一行”third blood”，通过diff命令可以了解到更多文件变更的信息，为提交代码前做一次检查。","link":"/2016/09/20/Git%E7%B3%BB%E5%88%97-3-hello-world/"},{"title":"Git系列-1-Git简介","text":"简介什么是Git？Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency Git是为了快速和高效处理任何大小工程而设计的免费开源的分布式版本控制系统。 Git简史同生活中的许多伟大事物一样，Git 诞生于一个极富纷争大举创新的年代。 Linux 内核开源项目有着为数众广的参与者。 绝大多数的 Linux 内核维护工作都花在了提交补丁和保存归档的繁琐事务上（1991－2002年间）。 到 2002 年，整个项目组开始启用一个专有的分布式版本控制系统 BitKeeper 来管理和维护代码。 到了 2005 年，开发 BitKeeper 的商业公司同 Linux 内核开源社区的合作关系结束，他们收回了 Linux 内核社区免费使用 BitKeeper 的权力。 这就迫使 Linux 开源社区（特别是 Linux 的缔造者 Linux Torvalds）基于使用 BitKcheper 时的经验教训，开发出自己的版本系统。 他们对新的系统制订了若干目标： 速度 简单的设计 对非线性开发模式的强力支持（允许成千上万个并行开发的分支） 完全分布式 有能力高效管理类似 Linux 内核一样的超大规模项目（速度和数据量） 自诞生于 2005 年以来，Git 日臻成熟完善，在高度易用的同时，仍然保留着初期设定的目标。 它的速度飞快，极其适合管理大项目，有着令人难以置信的非线性分支管理系统。 Git的诞生故事版 集中式VS分布式集中式（SVN、CVS等） 分布式（Git） 分布式VS集中式 分布式 集中式 网络依赖性 低 高 系统稳定性 低 高 存储扩展性 低 高","link":"/2016/09/20/Git%E7%B3%BB%E5%88%97-1-Git%E7%AE%80%E4%BB%8B/"},{"title":"Git系列-2-Git安装","text":"Git安装Note:这里的安装是安装Command-Line，并非Git工具。 如果需要安装Git工具可在这里找到 Linux Fedora123sudo yum install git Linux Debian123sudo apt-get install git Mac OSX官网下载 Windows官网下载 通过Github安装（Windows、Mac OSX）Github 测试安装是否成功123git --version 如果出现版本信息说明已经安装成功了。 Git配置安装按成后，可以进行Git的配置。 /etc/gitconfig –system ~/.gitconfig 或 ~/.config/git/config –global .git/config repository(当前仓库) repository &gt; golbal &gt; system 逐级的配置会覆盖上一层配置 123456git config --global user.name shuweigit config --global user.email shuvigoss@gmail.com#查看配置信息git config --list 这个配置很重要，因为在每次提交时都会带上你的姓名和邮箱。","link":"/2016/09/20/Git%E7%B3%BB%E5%88%97-2-Git%E5%AE%89%E8%A3%85/"},{"title":"Git系列-4-版本管理","text":"版本管理版本回退按照之前的操作，我们已经有3次commit，如何查看呢？ 123456789101112131415161718$ git logcommit a83beff902f6e37a0b51218d2fba3d911c4d1487Author: shuwei &lt;shuvigoss@gmail.com&gt;Date: Thu Aug 25 16:22:07 2016 +0800 third commitcommit afef6dd1fc89eb977a1c51de9f1c5a7de7ae5dd1Author: shuwei &lt;shuvigoss@gmail.com&gt;Date: Thu Aug 25 15:48:32 2016 +0800 second commitcommit 3d78e6b751d368c72d020ab8621c74aa97a1ff4eAuthor: shuwei &lt;shuvigoss@gmail.com&gt;Date: Thu Aug 25 15:33:39 2016 +0800 first commit 每一次的commit都有记录，包括时间、提交的描述、谁提交的。其中第一行的commit后跟的是每一次提交生成的SHA1串，我们可以管它叫commit id(版本号)，这个版本号是用来做版本回退的核心。比如我想将版本回退到第一次提交也就是first commit，那么如何做呢？ 12$ git reset --hard HEAD^^HEAD is now at 3d78e6b first commit 上面又用到了reset命令，其中HEAD这个参数就是你要将版本回退到当前HEAD往前的几个版本。比如： HEAD^ 回退到当前版本的前一版本 HEAD^^ 回退到当前版本的前前一版本 HEAD~10 回退到当前版本前10个版本 接下来查看当前工作区是否已经回退到我们需要的版本呢？ 12$ more README.mdfirst blood 确实已经是我们第一次提交的内容。 每个commit id 会有它的简写 比如原始commit id 为 3d78e6b751d368c72d020ab8621c74aa97a1ff4e 那么它可以使用前七位来表示3d78e6b 那么我们再使用git log查看当前的commit log会是什么样的呢？ 12345commit 3d78e6b751d368c72d020ab8621c74aa97a1ff4eAuthor: shuwei &lt;shuvigoss@gmail.com&gt;Date: Thu Aug 25 15:33:39 2016 +0800 first commit 我靠！我后边的内容丢了！完蛋了，回退错了~~不急，因为我们前边已经有最后一个版本的版本号了，那么再回退回去就好了。 1234567891011121314151617181920$ git reset --hard a83beffHEAD is now at a83beff third commit$ git logcommit a83beff902f6e37a0b51218d2fba3d911c4d1487Author: shuwei &lt;shuvigoss@gmail.com&gt;Date: Thu Aug 25 16:22:07 2016 +0800 third commitcommit afef6dd1fc89eb977a1c51de9f1c5a7de7ae5dd1Author: shuwei &lt;shuvigoss@gmail.com&gt;Date: Thu Aug 25 15:48:32 2016 +0800 second commitcommit 3d78e6b751d368c72d020ab8621c74aa97a1ff4eAuthor: shuwei &lt;shuvigoss@gmail.com&gt;Date: Thu Aug 25 15:33:39 2016 +0800 first commit 看，HEAD又回到最后一次提交的版本了。我们可以把上边2次reset操作通过下面这个图表来表示。 first commit second commit third commit commit id 3d78e6b afef6dd 3d78e6b origin HEAD reset1 HEAD reset2 HEAD 所以版本的回退Git做的就是将HEAD指针移动到相应的commit id，所以说Git的速度快就体现在这里。 假如你没有记录之前的版本内容，如何获取呢？ 123456$ git refloga83beff HEAD@{0}: reset: moving to a83beff3d78e6b HEAD@{1}: reset: moving to HEAD^^a83beff HEAD@{2}: commit: third commitafef6dd HEAD@{3}: commit: second commit3d78e6b HEAD@{4}: commit (initial): first commit reflog命令可以记录你每一次的命令。","link":"/2016/09/20/Git%E7%B3%BB%E5%88%97-4-%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/"},{"title":"Git系列-5-暂存区","text":"暂存区目前我们learngit目录结构如下： 12345-|learngit 工作区（Working Directory） -|.git 版本库（Repository） -|stage(index) 暂存区 -|master master分支 -|README.md 其中的暂存区里放的是当前所有add modify。","link":"/2016/09/20/Git%E7%B3%BB%E5%88%97-5-%E6%9A%82%E5%AD%98%E5%8C%BA/"},{"title":"Git系列-7-代码托管","text":"安装代码托管服务 如果做开源项目:首选肯定是github。但是由于github服务器在国外，也遇到过被墙的情况，备选可以将代码托管给开源中国、coding， 同时他们也支持付费托管私有仓库。 当然，做私有代码托管最好的方式还是搭建自己的Git代码托管服务，目前较好的服务有2个。 gitlab gogs gogs是新起的开源代码托管服务。是用go语言写的，支持跨平台，最主要是中国人主导的开源项目，维护以及更新非常及时。缺点是功能并没有太多，如果纯粹做一些代码管理是足够的。 gitlab是一个老牌的也是使用人数最多的开源代码托管服务，是用ruby on rails写的，稳定性和功能非常强大，几乎与github不相上下。 这里我选择使用gitlab做我的远程代码托管服务。gitlab的安装就不在这儿说了，需要的可自行在gitlab官网下载并安装。","link":"/2016/09/20/Git%E7%B3%BB%E5%88%97-7-%E4%BB%A3%E7%A0%81%E6%89%98%E7%AE%A1/"},{"title":"Git系列-8-远程仓库","text":"远程仓库http://10.211.55.9/ 本地gitlab地址 将本地learngit代码托管到gitlab1.首先先在gitlab上创建自己的project2.确认创建信息。 http协议回到learngit工作区。 12345678910111213141516$ git remote add origin http://10.211.55.9/shuwei/learngit.git$ git push -u origin masterUsername for 'http://10.211.55.9': shuweiPassword for 'http://shuwei@10.211.55.9':Counting objects: 19, done.Delta compression using up to 4 threads.Compressing objects: 100% (10/10), done.Writing objects: 100% (19/19), 1.45 KiB | 0 bytes/s, done.Total 19 (delta 2), reused 0 (delta 0)To http://10.211.55.9/shuwei/learngit.git * [new branch] master -&gt; masterBranch master set up to track remote branch master from origin.$ git remote -vorigin http://10.211.55.9/shuwei/learngit.git (fetch)origin http://10.211.55.9/shuwei/learngit.git (push) 通过http协议托管到gitlab时需要输入用户名密码，这个就是你gitlab登录用户的用户名密码。如果觉得输入账号密码麻烦，可以使用git协议。 git协议在完成将本地learngit代码托管到gitlab后，可以生成本地公钥。 在用户主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有id_rsa和id_rsa.pub这两个文件，如果已经有了，可直接跳到下一步。如果没有，打开Shell（Windows下打开Git Bash），创建SSH Key： 123$ ssh-keygen -t rsa -C &quot;shuvigoss@gmail.com&quot;一路回车cat ~/.ssh/id_rsa.pub 可以看到公钥信息，copy 打开用户Profile setting 将公钥配置上 12345678910$ git remote add origin git@10.211.55.9:shuwei/learngit.git$ git push -u origin masterCounting objects: 19, done.Delta compression using up to 4 threads.Compressing objects: 100% (10/10), done.Writing objects: 100% (19/19), 1.45 KiB | 0 bytes/s, done.Total 19 (delta 2), reused 0 (delta 0)To git@10.211.55.9:shuwei/learngit.git * [new branch] master -&gt; masterBranch master set up to track remote branch master from origin. 这样免密的推送就完成了。 clone远程仓库到本地123456789$ mkdir learngit1$ git clone git@10.211.55.9:shuwei/learngit.git learngit1/Cloning into 'learngit1'...remote: Counting objects: 19, done.remote: Compressing objects: 100% (10/10), done.remote: Total 19 (delta 2), reused 0 (delta 0)Receiving objects: 100% (19/19), done.Resolving deltas: 100% (2/2), done.Checking connectivity... done. clone命令可以指定clone到哪个文件夹","link":"/2016/09/20/Git%E7%B3%BB%E5%88%97-8-%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93/"},{"title":"通过 Hexo 创建自己的Blog","text":"选型很早以前就想搭建一个自己的Blog，记录一些工作中沉淀下来的东西。最近有些时间,So…动起来吧！ 从jekyll到hexo刚开始选择使用jekyll,搞了半天各种不顺,再查阅资料的过程中接触到了hexo,而且对比两者,我也选择了hexo. 安装1$ sudo npm install -g hexo-cli 123456$ hexo init my-blog$ cd my-blog$ npm install$ git clone https://github.com/tufu9441/maupassant-hexo.git themes/maupassant --depth 1$ npm install hexo-renderer-jade --save$ npm install hexo-renderer-sass --save 由于hexo完全基于NodeJs,所以比较简单.这里我选择了tufu9441的Theme变种,感觉不错. _config.yml(根目录) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Sitetitle: Shuvigoss'Blogsubtitle: 好记性不如烂笔头description: 记录一些总是会忘掉的东西author: Shuvigosslanguage: zh-CNtimezone:# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://yoursite.comroot: /permalink: :year/:month/:day/:title/permalink_defaults:# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace:# Category &amp; Tagdefault_category: uncategorizedcategory_map: hexo:hexo java:javatag_map:# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: maupassant# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: _config.yml(themes/maupassant/_config.yml) 1234567891011121314151617181920212223242526272829303132333435363738394041fancybox: true ## If you want to use fancybox please set the value to true.duoshuo: ## Your duoshuo_shortname, e.g. usernamedisqus: ## Your disqus_shortname, e.g. usernamegoogle_search: true ## Use Google search, true/false.baidu_search: ## Use Baidu search, true/false.swiftype: ## Your swiftype_key, e.g. m7b11ZrsT8Me7gzApciTtinysou: ## Your tinysou_key, e.g. 4ac092ad8d749fdc6293self_search: ## Use a jQuery-based local search engine, true/false.google_analytics: ## Your Google Analytics tracking id, e.g. UA-42425684-2baidu_analytics: ## Your Baidu Analytics tracking id, e.g. 8006843039519956000show_category_count: false ## If you want to show the count of categories in the sidebar widget please set the value to true.shareto: true ## If you want to use the share button please set the value to true.busuanzi: true ## If you want to use Busuanzi page views please set the value to true.widgets_on_small_screens: false ## Set to true to enable widgets on small screens.menu: - page: home directory: . icon: fa-home - page: archive directory: archives/ icon: fa-archive # - page: about # directory: about/ # icon: fa-user # - page: rss # directory: atom.xml # icon: fa-rsswidgets: ## Six widgets in sidebar provided: search, category, tag, recent_posts, rencent_comments and links. - search - category - recent_posts# Static filesjs: jscss: css# Theme versionversion: 0.0.0 这里边没有改太多,后续再做优化吧. 1$ hexo server 通过访问http://localhost:4000/就可以看到页面了. 发布到Github 通过https://pages.github.com/创建自己的Pages 在blog下安装npm install hexo-deployer-git --save,用于发布到github 修改根目录下的_config.yml1234deploy: type: git repo: git@github.com:shuvigoss/shuvigoss.github.io.git branch: master hexo g &amp; hexo d 进行生成和发布. 域名绑定 在阿里云注册了个shuvigoss.win的域名(10年50块,挺便宜:) $ ping shuvigoss.github.io 获得该域名IP 在阿里云上绑定IP即可 参考文章https://www.haomwei.com/technology/maupassant-hexo.htmlhttps://hexo.io/zh-cn/docs/setup.htmlhttp://www.jianshu.com/p/ce1619874d34https://segmentfault.com/a/1190000002398039https://pages.github.com/http://www.jianshu.com/p/35e197cb1273","link":"/2016/09/20/%E9%80%9A%E8%BF%87-Hexo-%E5%88%9B%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84Blog/"},{"title":"Git系列-9-分支管理","text":"分支管理分支管理是VCS必备的技能，Git分支管理是他的一大特点，很快而且高效。 创建分支1234567891011121314151617181920212223242526$ git checkout -b devSwitched to a new branch 'dev'$ git branch* dev master$ echo &quot;dev&quot; &gt;&gt; README.md$ git add README.md$ git commit -m 'branch dev create'[dev fb43350] branch dev create 1 file changed, 1 insertion(+)$ git push -u origin devCounting objects: 3, done.Delta compression using up to 4 threads.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 271 bytes | 0 bytes/s, done.Total 3 (delta 1), reused 0 (delta 0)remote:remote: Create merge request for dev:remote: http://ubuntu/shuwei/learngit/merge_requests/new?merge_request%5Bsource_branch%5D=devremote:To git@10.211.55.9:shuwei/learngit.git * [new branch] dev -&gt; devBranch dev set up to track remote branch dev from origin. 123-b参数表示创建并切换$ git branch dev$ git checkout dev branch dev-&gt;checkout dev-&gt;modify-&gt;add-&gt;commit-&gt;push dev 查看gitlab上是否已经增加了dev分支 确实，dev分支已经创建成功了。还可以比对分支与master之间的差异 合并分支Note：和并前必须先切换到你要合并到的目标分支 123456789$ git checkout masterSwitched to branch 'master'Your branch is up-to-date with 'origin/master'.$ git merge devUpdating 0b032b6..fb43350Fast-forward README.md | 1 + 1 file changed, 1 insertion(+) 删除分支这样就完成了一次分支合并，如果需要可以在合并完成后删除dev分支$ git branch -d dev 本地分支 $ git push origin --delete dev 远程分支","link":"/2016/09/20/Git%E7%B3%BB%E5%88%97-9-%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86/"},{"title":"Git系列-6-修改与撤销","text":"修改管理修改Git是面向修改的，这个特性是有别于其他的VCS，怎么来理解Git的是面向修改的呢？通过以下这个例子你就明白了。 12345678910111213141516$ echo &quot;fourth blood&quot; &gt;&gt; README.md$ git add README.md$ echo &quot;fifth blood&quot; &gt;&gt; README.md$ git commit -m 'fourth and fifth commit'[master cc9cccf] fourth and fifth commit 1 file changed, 1 insertion(+)$ git statusOn branch masterChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: README.mdno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 我们可以发现add fourth blood 后执行了一次add，再没有执行commit之前又增加了fifth blood，最终执行commit后发现当前工作区的状态并没有把fifth blood 的修改提交上去。 所以我们要记住一次commit是将暂存区提交代码而不会提交工作区。 撤销修改有2种修改需要撤销： add no add 针对add后的reset我们前边已经做过了git reset HEAD &lt;file&gt;...可以完成对add的撤销。 如果当前工作区中没有add modify，可以直接使用git checkout -- &lt;file&gt;...来完成对工作区的清理。 12345678910111213141516$ echo &quot;a&quot; &gt;&gt; README.md$ more README.mdfirst bloodsecond bloodthird bloodfourth bloodfifth blooda$ git checkout -- README.md$ more README.mdfirst bloodsecond bloodthird bloodfourth bloodfifth blood 删除文件1234567891011121314$ touch test.txt$ git add test.txt$ git commit -m 'add test.txt'[master e530961] add test.txt 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 test.txt$ git rm test.txtrm 'test.txt'$ git commit -m 'rm test.txt'[master 00ddca9] rm test.txt 1 file changed, 0 insertions(+), 0 deletions(-) delete mode 100644 test.txt","link":"/2016/09/20/Git%E7%B3%BB%E5%88%97-6-%E4%BF%AE%E6%94%B9%E4%B8%8E%E6%92%A4%E9%94%80/"},{"title":"Git系列-12-tag管理","text":"标签管理标签就是对commit id加上一个别名。比如上次提交的commit id为622493706ab447b6bb37e4e2a2f276a20fed2ab4，如果我想把这次版本进行发布，后期又能很清楚的知道这次版本发布了什么。那么使用Tag就很简单了。 给当前版本打Tag12345678910111213141516171819202122$ git tag v1.0$ git tagv1.0$ git show v1.0commit a44ba6aa022fea773e3a157ee683abc25e255d8dAuthor: shuwei &lt;shuvigoss@gmail.com&gt;Date: Fri Aug 26 16:02:31 2016 +0800 mod test.txtdiff --git a/test.txt b/test.txtindex 8b13789..6b673e8 100644--- a/test.txt+++ b/test.txt@@ -1 +1,2 @@推送tag到upstream$ git push origin --tagsTotal 0 (delta 0), reused 0 (delta 0)To git@10.211.55.9:shuwei/learngit.git * [new tag] v1.0 -&gt; v1.0 给历史版本打Tag123456789101112131415161718192021222324$ git log --pretty=oneline --abbrev-commita44ba6a mod test.txt093885d add test.txtf25f3a7 add 26714338 add 1fb43350 branch dev create0b032b6 rm test.txte530961 add test.txt2458334 fourth and fifth commitcc9cccf fourth and fifth commita83beff third commitafef6dd second commit3d78e6b first commit$ git tag v0.9 2458334$ git tagv0.9v1.0推送tag到upstream$ git push origin --tagsTotal 0 (delta 0), reused 0 (delta 0)To git@10.211.55.9:shuwei/learngit.git * [new tag] v0.9 -&gt; v0.9 这两次的版本在gitlab上都可以体现。","link":"/2016/09/20/Git%E7%B3%BB%E5%88%97-12-tag%E7%AE%A1%E7%90%86/"},{"title":"Git系列-11-代码同步","text":"代码更新git pull &amp; git fetch git pull = git fetch + git merge $ git fetch &lt;远程主机名&gt; &lt;分支名&gt; 12345$ git fetch取回所有内容，包括分支，tag等$ git fetch origin master将origin(upstream) 的master分支取回本地 git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 12$ git pull origin next:master将origin的next fetch下来与本地master分支合并。 大部分情况下，可以直接使用pull命令进行fetch+merge操作，如果你本地代码会有一些测试分支等建议使用fetch手动进行合并，否则可能会覆盖掉你本地的一些内容。","link":"/2016/09/20/Git%E7%B3%BB%E5%88%97-11-%E4%BB%A3%E7%A0%81%E5%90%8C%E6%AD%A5/"},{"title":"Git系列-13-Gitlab","text":"gitlab简介详细内容可查看gitlab官方文档.这里我介绍一些很常用的功能。 权限管理 root 可以做任何事情。可删除Admin 用户 Admin 与root 类似 normal 普通用户 新增用户 group &amp; projectgroup是project的合集。一个group下会有多个project group 权限 Public ：未登录用户可以clone Internal ：只有登录用户可以clone Private ：只有属于这个group的用户可见 project 权限 Public ：未登录用户可以clone Internal ：只有登录用户可以clone Private ：只有属于这个group的用户可见 将用户添加到group 总体来说gitlab权限管理比较简单，与github很相近。 神器APIgitlab提供了大量的api，可以配合自己的系统进行对接操作。 Award Emoji Branches Builds Build triggers Build Variables Commits Deploy Keys Groups Group Access Requests Group Members Issues Keys Labels Merge Requests Milestones Open source license templates Namespaces Notes (comments) Pipelines Projects including setting Webhooks Project Access Requests Project Members Project Snippets Repositories Repository Files Runners Services Session Settings Sidekiq metrics System Hooks Tags Users Todos wikigitlab、github都内置了wiki 支持Markdown，RDoc，AsciiDoc格式文档，非常方便。 其他 可以使用runner做持续集成，发布等。 SystemHooks 对于增加project或者group会有系统通知 Message 可以对全局用户发送通知 … and so on","link":"/2016/09/20/Git%E7%B3%BB%E5%88%97-13-Gitlab/"},{"title":"Git系列-10-分支实战","text":"分支操作实战创建分支test12$ git checkout -b testSwitched to a new branch 'test' 在test分支添加test.txt文件123456$ echo &quot;&quot; &gt;&gt; test.txt$ git add test.txt$ git commit -m 'add test.txt'[test 093885d] add test.txt 1 file changed, 1 insertion(+) create mode 100644 test.txt 推送test分支到upstream123456789101112$ git push origin testCounting objects: 3, done.Delta compression using up to 4 threads.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 274 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)remote:remote: Create merge request for test:remote: http://ubuntu/shuwei/learngit/merge_requests/new?merge_request%5Bsource_branch%5D=testremote:To git@10.211.55.9:shuwei/learngit.git * [new branch] test -&gt; test 再次修改test分支test.txt文件12345$ echo &quot;a&quot; &gt;&gt; test.txt$ git add test.txt$ git commit -m 'mod test.txt'[test a44ba6a] mod test.txt 1 file changed, 1 insertion(+) 将修改推送到upstream123456789101112$ git push origin testCounting objects: 3, done.Delta compression using up to 4 threads.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 274 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)remote:remote: Create merge request for test:remote: http://ubuntu/shuwei/learngit/merge_requests/new?merge_request%5Bsource_branch%5D=testremote:To git@10.211.55.9:shuwei/learngit.git 093885d..a44ba6a test -&gt; test 切换到master分支123$ git checkout masterSwitched to branch 'master'Your branch is up-to-date with 'origin/master'. 合并test分支到master123456$ git merge testUpdating f25f3a7..a44ba6aFast-forward test.txt | 2 ++ 1 file changed, 2 insertions(+) create mode 100644 test.txt 合并分支时，加上--no-ff参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而fast forward合并就看不出来曾经做过合并。 推送master到upstream1234$ git push origin masterTotal 0 (delta 0), reused 0 (delta 0)To git@10.211.55.9:shuwei/learngit.git f25f3a7..a44ba6a master -&gt; master 删除本地test分支和upstream test分支123456$ git push origin --delete testTo git@10.211.55.9:shuwei/learngit.git - [deleted] test$ git branch -d testDeleted branch test (was a44ba6a). 配合上图就能更明了的看清楚本地与upstream的分支变化。 类似这个时间线的截图工具是GitUp 代码冲突如果在test分支修改过程中，master分支也对同一文件进行了修改，可能就会出现代码冲突，这种情况下就需要手动进行代码合并了，合并完成后再提交。 冲突情况大部分都是对同一文件的修改，格式大致如下： 12345&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADaaaa=======bbb&gt;&gt;&gt;&gt;&gt;&gt;&gt; test 那就需要人手动修改冲突文件并决定哪些要留哪些不需要。 分支策略(理想情况)在实际开发中，我们应该按照几个基本原则进行分支管理： 首先，master分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活； 那在哪干活呢？干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本； 你和你的小伙伴们每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以了。 所以，团队合作的分支看起来就像这样： 但实际上… 拣选合并(cherry-picking)：1234$ git checkout master$ git cherry-pick 321d76for$ git cherry-pick -n 321d76f 32sd76d 拣选合并用于在非master分支中选择需要的commit id来进行合并，可能会有一定的冲突，解决就好。","link":"/2016/09/20/Git%E7%B3%BB%E5%88%97-10-%E5%88%86%E6%94%AF%E5%AE%9E%E6%88%98/"},{"title":"【golang】 slice","text":"使用golang已经快2年了，一直没有好好整理过基础知识，这次也好好整理一下，从最基本的slice开始，也把之前的一些疑惑进行自我解答 :) 数组1234567func TestArray(t *testing.T) { s := [2]int{1, 2} fmt.Printf(&quot;type is %T, value is %v\\n&quot;, s, s)}type is [2]int, value is [1 2] 数组是不可变的,在go中基本上用的很少 切片 Slice切片创建123456789101112131415161718192021222324252627func TestSliceNew(t *testing.T) { //No.1 s1 := []int{1, 2, 3} fmt.Printf(&quot;len is %d, cap is %d , is nil %t\\n&quot;, len(s1), cap(s1), s1 == nil) //No.2 s2 := make([]int, 0, 10) fmt.Printf(&quot;len is %d, cap is %d , is nil %t\\n&quot;, len(s2), cap(s2), s2 == nil) //No.3 var s3 []int fmt.Printf(&quot;len is %d, cap is %d , is nil %t\\n&quot;, len(s3), cap(s3), s3 == nil) //No.4 // new 函数返回是指针类型，所以需要使用 * 号来解引用 s4 := *new([]int) fmt.Printf(&quot;len is %d, cap is %d , is nil %t\\n&quot;, len(s3), cap(s3), s4 == nil)}=== RUN TestSliceNewlen is 3, cap is 3 , is nil falselen is 0, cap is 10 , is nil falselen is 0, cap is 0 , is nil truelen is 0, cap is 0 , is nil true--- PASS: TestSliceNew (0.00s)PASS 总共常用的是3中方式，其中第三种，第四种就不要用了，这里有2中类型，1个叫”nil切片”,1个叫”empty切片”，官方推荐使用nil切片，也就是var s []int这种方式 The former declares a nil slice value, while the latter is non-nil but zero-length. They are functionally equivalent—their len and cap are both zero—but the nil slice is the preferred style. 那么这两种有什么区别呢？其实很简单，empty切片在创建时，都会使用同一内存地址来标识，runtime/malloc.go下边就这么写的 1234567891011121314func mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer { if gcphase == _GCmarktermination { throw(&quot;mallocgc called with gcphase == _GCmarktermination&quot;) } if size == 0 { return unsafe.Pointer(&amp;zerobase) } //xxxx}// base address for all 0-byte allocationsvar zerobase uintptr appendappend是最常用的方式，先来看这段代码 1234567891011121314151617181920212223242526272829303132333435func TestSlice1(t *testing.T) { s := make([]int, 0) fmt.Printf(&quot;len is %d, cap is %d &quot;, len(s), cap(s)) hdr := (*reflect.SliceHeader)(unsafe.Pointer(&amp;s)) fmt.Printf(&quot;ptr is %x \\n&quot;, hdr.Data) s = append(s, 1) fmt.Printf(&quot;len is %d, cap is %d &quot;, len(s), cap(s)) hdr = (*reflect.SliceHeader)(unsafe.Pointer(&amp;s)) fmt.Printf(&quot;ptr is %x \\n&quot;, hdr.Data) s = append(s, 2) fmt.Printf(&quot;len is %d, cap is %d &quot;, len(s), cap(s)) hdr = (*reflect.SliceHeader)(unsafe.Pointer(&amp;s)) fmt.Printf(&quot;ptr is %x \\n&quot;, hdr.Data) s = append(s, 3) fmt.Printf(&quot;len is %d, cap is %d &quot;, len(s), cap(s)) hdr = (*reflect.SliceHeader)(unsafe.Pointer(&amp;s)) fmt.Printf(&quot;ptr is %x \\n&quot;, hdr.Data) s = append(s, 4) fmt.Printf(&quot;len is %d, cap is %d &quot;, len(s), cap(s)) hdr = (*reflect.SliceHeader)(unsafe.Pointer(&amp;s)) fmt.Printf(&quot;ptr is %x \\n&quot;, hdr.Data)}=== RUN TestSlice1len is 0, cap is 0 ptr is c00006ae58 len is 1, cap is 1 ptr is c0000162c0 len is 2, cap is 2 ptr is c0000162d0 len is 3, cap is 4 ptr is c00001e100 len is 4, cap is 4 ptr is c00001e100 --- PASS: TestSlice1 (0.00s)PASS 从输出结果看，在append后，前3次的slice指针都变了，说明产生了新的slice，在slice的源码中可以看到如下代码runtime/slice.go growslice 1234567891011121314151617181920newcap := old.capdoublecap := newcap + newcapif cap &gt; doublecap { newcap = cap} else { if old.cap &lt; 1024 { newcap = doublecap } else { // Check 0 &lt; newcap to detect overflow // and prevent an infinite loop. for 0 &lt; newcap &amp;&amp; newcap &lt; cap { newcap += newcap / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap &lt;= 0 { newcap = cap } }} 可以这么解读，如果cap在1024下，每次slice的膨胀会乘以2，当超过1024后，会变为1.25（实际上不准确，后边有内存补齐的处理，基本维持在1.3左右） 那么不难看出，创建一个空slice后，append操作的cap为0 -&gt; 1 -&gt; 2 -&gt; 4 -&gt; 8，也就意味着第1、2、3次append都会产生新的slice，4、5次就会使用同一slice slice函数传递之前这个是我最不清楚的，也是一知半解，直接看一下代码 1234567891011121314151617181920212223242526func TestSlice2(t *testing.T) { s := make([]int, 0, 8) s = append(s, []int{1, 2, 3, 4, 5}...) fmt.Printf(&quot;len is %d, cap is %d \\n&quot;, len(s), cap(s)) modify(s) fmt.Printf(&quot;修改后的值 %v\\n&quot;, s) appendSlice(s) fmt.Printf(&quot;append后的值 %v\\n&quot;, s)}func modify(s []int) { s[0] = 9}func appendSlice(s []int) { s = append(s, 6)}=== RUN TestSlice2len is 5, cap is 8 修改后的值 [9 2 3 4 5]append后的值 [9 2 3 4 5]--- PASS: TestSlice2 (0.00s)PASS 在modify函数内，改变了s[0]为9，输出后确实是，变化了，说明在传递时是”引用传递”(这里先用这个词来描述),但appendSlice操作后，并没有发生变化，难道不是”引用传递”吗？为什么会没有append成功？ 首先这里先直接说结论，go中没有引用传递，只有值传递 https://golang.org/ref/spec#Calls In a function call, the function value and arguments are evaluated in the usual order. After they are evaluated, the parameters of the call are passed by value to the function and the called function begins execution. The return parameters of the function are passed by value back to the caller when the function returns. 那么在go中有3个数据结构是特殊的，那就是map、slice、chan他们的类型叫做reference types,他们是”引用类型”，但在函数传递过程中，并不是”引用类型”，这块之前比较迷茫，现在就清晰了 Map types are reference types, like pointers or slices, and so the value of m above is nil; it doesn't point to an initialized map. A nil map behaves like an empty map when reading, but attempts to write to a nil map will cause a runtime panic; don't do that. To initialize a map, use the built in make function: https://blog.golang.org/maps 先看下slice的结构定义，这里有2个，具体什么区别暂时还不清楚，但原理基本一样 123456789101112131415// runtime/slice.gotype slice struct { array unsafe.Pointer len int cap int}// reflect/value.gotype SliceHeader struct { Data uintptr Len int Cap int}// 基本上都是1个指针，指着数组第一位内存地址 基于上述，修改一下之前的测试代码，就可以清楚的看出来参数传递的端倪 1234567891011121314151617181920212223242526272829func TestSlice2(t *testing.T) { s := make([]int, 0, 8) s = append(s, []int{1, 2, 3, 4, 5}...) hdr := (*reflect.SliceHeader)(unsafe.Pointer(&amp;s)) fmt.Printf(&quot;slice A len is %d, cap is %d , point is %p, 头指针为 %d\\n&quot;, len(s), cap(s), &amp;s, hdr.Data) appendSlice(s) //获取s的SliceHeader指针 hdr = (*reflect.SliceHeader)(unsafe.Pointer(&amp;s)) //将Data转为int类型的数组，长度为8 newData := *(*[8]int)(unsafe.Pointer(hdr.Data)) fmt.Printf(&quot;输出s的第六位值为 %d\\n&quot;, newData[5])}func appendSlice(s []int) { hdr := (*reflect.SliceHeader)(unsafe.Pointer(&amp;s)) fmt.Printf(&quot;slice B len is %d, cap is %d , point is %p, 头指针为 %d\\n&quot;, len(s), cap(s), &amp;s, hdr.Data) s = append(s, 6)}=== RUN TestSlice2slice A len is 5, cap is 8 , point is 0xc0000ba030, 头指针为 824634409344slice B len is 5, cap is 8 , point is 0xc0000ba048, 头指针为 824634409344输出s的第六位值为 6--- PASS: TestSlice2 (0.00s)PASS 可以看出来，入参后，slice的指针为0xc00000c060，与0xc00000c048是不同的，说明传递的是值，也就是s的一份拷贝,然后slice下的Data指针却是一致的824633852544，说明指向的都是同一份内存地址 在appendSlice函数内进行了append,只是对slice B进行了append，并没有影响slice A,但是通过反射，将Data指针强转为长度为8的数组后，输出第5位值后发现，其实append是成功的，只是slice A并没有更新他的len,其实还可以再用如下方法进行修改 1234 hdr.Len = 6 fmt.Println(s[5])6 原理是一致的 总结 slice分为”nil切片”、”empty切片”，建议使用”nil切片” slice扩容在1024前是2倍，1024后是1.25倍，为了减少copy尽量指定slice长度 slice作为参数传递时，传递的是原slice的一份copy，只是data数据指针为同一数组指针","link":"/2021/04/08/%E3%80%90golang%E3%80%91-%20slice/"}],"tags":[{"name":"HttpComponents","slug":"HttpComponents","link":"/tags/HttpComponents/"},{"name":"ReentrantLock","slug":"ReentrantLock","link":"/tags/ReentrantLock/"},{"name":"Distributed Lock","slug":"Distributed-Lock","link":"/tags/Distributed-Lock/"},{"name":"Golang","slug":"Golang","link":"/tags/Golang/"}],"categories":[{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Zookeeper","slug":"Zookeeper","link":"/categories/Zookeeper/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"}]}